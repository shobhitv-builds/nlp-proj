{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetches stock data from Yahoo Finance and builds dataset from the augmented tweet dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "biCMiZqS690M"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import yfinance as yf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WLIoOXblQRku"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Gets the stock data from Yahoo Finance for given tickerSymbol, startDate, endDate\n",
        "'''\n",
        "def getStockPriceDataframe(tickerSymbol, startDate, endDate):\n",
        "  # fetch data\n",
        "  data = yf.Ticker(tickerSymbol).history(start=startDate, end=endDate)\n",
        "\n",
        "  # drop unnecessary cols\n",
        "  data = data.drop('Dividends', axis=1)\n",
        "  data = data.drop('Stock Splits', axis=1)\n",
        "\n",
        "  # reindex\n",
        "  data['Timestamp'] = data.index.array\n",
        "  data.index = range(0, len(data))\n",
        "\n",
        "  # calc derrived attributes\n",
        "  data['Delta'] = data['Close'] - data['Open']\n",
        "  data['Volatility'] = 0.0\n",
        "  data['AvgVolatility'] = 0.0\n",
        "  data['Momentum'] = 0.0\n",
        "\n",
        "  for idx in range(1, len(data)):\n",
        "    data.at[idx, 'Volatility'] = (data.at[idx - 1, 'Close'] - data.at[idx, 'Close']) / data.at[idx - 1, 'Close']\n",
        "    data.at[idx, 'Momentum'] = 1.0 if (data.at[idx, 'Close'] > data.at[idx - 1, 'Close']) else 0.0\n",
        "    if idx > 5:\n",
        "      data.at[idx, 'AvgVolatility'] = data.iloc[idx-5:idx]['Volatility'].mean()\n",
        "  \n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gCxR9F8RQ5eJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSFT\n",
            "AAPL\n",
            "AMZN\n",
            "META\n",
            "BRK-B\n",
            "GOOG\n",
            "JNJ\n",
            "JPM\n",
            "V\n",
            "PG\n",
            "MA\n",
            "INTC\n",
            "UNH\n",
            "BAC\n",
            "T\n",
            "HD\n",
            "XOM\n",
            "DIS\n",
            "VZ\n",
            "KO\n",
            "MRK\n",
            "CMCSA\n",
            "CVX\n",
            "PEP\n",
            "PFE\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Get the ticker symbols we're interested in\n",
        "'''\n",
        "\n",
        "stock_tickers = open('../data/stock-tickers.txt', 'r')\n",
        "tickers = stock_tickers.readlines()\n",
        "\n",
        "stock_tickers.close()\n",
        "\n",
        "# Strips the newline character\n",
        "for ticker in tickers:\n",
        "    ticker = ticker.replace('\\n', '').replace('$', '')\n",
        "    df_prices = getStockPriceDataframe(tickerSymbol=ticker, startDate='2020-04-09', endDate='2020-07-16')\n",
        "    ticker = ticker.lower()\n",
        "    df_prices.to_csv('stock_prices_' + ticker + '.csv', sep=';', line_terminator='\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Calculate sentiment scores as p / (p + n)\n",
        "'''\n",
        "\n",
        "stock_tickers = open('../data/stock-tickers.txt', 'r')\n",
        "tickers = stock_tickers.readlines()\n",
        "stock_tickers.close()\n",
        "\n",
        "data_by_ticker = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    ticker = ticker.replace('\\n', '').replace('$', '').lower()\n",
        "    new_feature_dict = {}\n",
        "    with open(\"../data/regression-task/sentiments-by-date/\" + ticker + \"_sentiments.json\") as sentf:\n",
        "        sent_dict = json.load(sentf)\n",
        "        for key, item in sent_dict.items():\n",
        "            new_feature_dict[key] = item['p'] / (item['p'] + item['n'])\n",
        "    data_by_ticker[ticker] = new_feature_dict\n",
        "\n",
        "with open(\"../data/regression-task/new_sentiment_features.json\", \"w\") as masterf:\n",
        "    json.dump(data_by_ticker, masterf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Augments the dataset by grouping tweets by ticker symbol and date\n",
        "'''\n",
        "\n",
        "stock_tickers = open('../data/stock-tickers.txt', 'r')\n",
        "tickers = stock_tickers.readlines()\n",
        "\n",
        "stock_tickers.close()\n",
        "\n",
        "for ticker in tickers:\n",
        "    ticker = ticker.replace('\\n', '').replace('$', '').lower()\n",
        "    file_name = 'stock_prices_' + ticker + '.csv'\n",
        "    df_prices = pd.read_csv(\"../data/regression-task/stock-price-data/\" + file_name, sep=';', lineterminator='\\n')\n",
        "    new_features = []\n",
        "    num_matches = 0\n",
        "    sum = 0\n",
        "    for i, row in df_prices.iterrows():\n",
        "        date = row['Timestamp']\n",
        "        f = ''\n",
        "        if date in data_by_ticker[ticker]:\n",
        "            num_matches += 1\n",
        "            f = data_by_ticker[ticker][date]\n",
        "            sum = sum + f\n",
        "        new_features.append(f)\n",
        "    avg_of_feature = sum/num_matches\n",
        "    for i in range(len(new_features)):\n",
        "        if new_features[i] == '':\n",
        "            new_features[i] = avg_of_feature\n",
        "\n",
        "    df_prices['positive_sentiment'] = new_features\n",
        "    df_prices.to_csv('../data/regression-task/stock-price-data-augmented/stock_prices_' + ticker + '_augmented.csv', sep=';', line_terminator='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Finally write the augmented dataset\n",
        "'''\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "all_files = glob.glob(os.path.join(\"../data/regression-task/stock-price-data-augmented/\", \"*.csv\"))\n",
        "df = pd.concat((pd.read_csv(f, sep=';', lineterminator='\\n') for f in all_files), ignore_index=True)\n",
        "df.shape\n",
        "df.to_csv('../data/regression-task/master-regression-dataset.csv', sep=';', line_terminator='\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "stock_price_dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
